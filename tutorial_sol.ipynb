{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Let's get started\n",
    "## Importing some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_digit(img):\n",
    "    \"\"\"\n",
    "    Display the vector as a 28*28 grayscale image.\n",
    "    \"\"\"\n",
    "    img = img.reshape((28,28))\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectoried_generate_onehot_vector(labels):\n",
    "    \"\"\"\n",
    "    Returns the onehot encoding of the labels. This is a vectorized version of the function.\n",
    "    \"\"\"\n",
    "    onehot = np.zeros((len(labels), 10))\n",
    "    onehot[np.arange(len(labels)), labels] = 1\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_onehot_vector(labels):\n",
    "    \"\"\"\n",
    "    Returns the onehot encoding of the labels.\n",
    "    \"\"\"\n",
    "    num_samples = len(labels)\n",
    "    onehot = np.zeros((num_samples, 10))\n",
    "    for i in range(num_samples):\n",
    "        label = labels[i]\n",
    "        onehot[i, label] = 1\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training set and testing set\n",
    "The dataset we are working with in this tutorial is the MNIST handwritten digit dataset.\n",
    "There are 60000 training examples and 10000 testing examples. We will only use 20000 of the trainig examples and 2000 of the testing examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"X_train.npy\")[:20000,:]\n",
    "y_train = np.load(\"y_train.npy\")[:20000]\n",
    "X_test = np.load(\"X_test.npy\")[:2000,:]\n",
    "y_test = np.load(\"y_test.npy\")[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the labels to one hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = generate_onehot_vector(y_train)\n",
    "y_test_onehot = vectoried_generate_onehot_vector(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Setting up the neural network\n",
    "\n",
    "In this tutorial, we will use a neural network with three fully connected hidden layers. We will explore how different hyperparamter choices affect the performance of our neural network. Let's first set up some hyperparameters for our net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "iterations = 1000\n",
    "layer_1_nodes = 150\n",
    "layer_2_nodes = 150\n",
    "layer_3_nodes = 150\n",
    "layer_4_nodes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up neural network\n",
    "tf.placeholder is a variable to which we will assign values to at the later stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the layers of our neural net to our [\"Computational Graph\"]([https://www.tensorflow.org/programmers_guide/graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.random_normal(shape=[784, layer_1_nodes], \n",
    "                                           dtype=tf.float32,\n",
    "                                           stddev=1e-1),\n",
    "                                           name=\"weights1\")\n",
    "b1 = tf.Variable(tf.constant(0.0, shape=[layer_1_nodes], dtype=tf.float32), name=\"biases1\")\n",
    "\n",
    "layer_1_output = tf.nn.relu(tf.matmul(X, w1) + b1)\n",
    "\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal(shape=[layer_1_nodes, layer_2_nodes], \n",
    "                                           dtype=tf.float32,\n",
    "                                           stddev=1e-1),\n",
    "                                           name=\"weights2\")\n",
    "b2 = tf.Variable(tf.constant(0.0, shape=[layer_2_nodes], dtype=tf.float32), name=\"biases2\")\n",
    "\n",
    "layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, w2) + b2)\n",
    "\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal(shape=[layer_2_nodes, layer_3_nodes], \n",
    "                                           dtype=tf.float32,\n",
    "                                           stddev=1e-1),\n",
    "                                           name=\"weights3\")\n",
    "b3 = tf.Variable(tf.constant(0.0, shape=[layer_3_nodes], dtype=tf.float32), name=\"biases3\")\n",
    "\n",
    "layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, w3) + b3)\n",
    "\n",
    "w4 = tf.Variable(tf.random_normal(shape=[layer_3_nodes, layer_4_nodes], \n",
    "                                           dtype=tf.float32,\n",
    "                                           stddev=1e-1),\n",
    "                                           name=\"weights4\")\n",
    "b4 = tf.Variable(tf.constant(0.0, shape=[layer_4_nodes], dtype=tf.float32), name=\"biases4\")\n",
    "\n",
    "layer_4_output = tf.matmul(layer_3_output, w4) + b4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choices of loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = layer_4_output\n",
    "cost = tf.losses.softmax_cross_entropy(logits=prediction, onehot_labels=Y)\n",
    "# cost = tf.reduce_mean(tf.squared_difference(prediction, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 0, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.18845\n",
      "The current cost: train 2.28366756439209, test 2.2936317920684814\n",
      "\n",
      "At iteration 20, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.72815\n",
      "The current cost: train 1.0279886722564697, test 1.176077127456665\n",
      "\n",
      "At iteration 40, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.82265\n",
      "The current cost: train 0.6141048669815063, test 0.7451848387718201\n",
      "\n",
      "At iteration 60, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.84905\n",
      "The current cost: train 0.5015817284584045, test 0.6308501958847046\n",
      "\n",
      "At iteration 80, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.8696\n",
      "The current cost: train 0.43713095784187317, test 0.5489780902862549\n",
      "\n",
      "At iteration 100, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.8928\n",
      "The current cost: train 0.3713492155075073, test 0.47697290778160095\n",
      "\n",
      "At iteration 120, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9021\n",
      "The current cost: train 0.33929166197776794, test 0.44184473156929016\n",
      "\n",
      "At iteration 140, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.90885\n",
      "The current cost: train 0.314525306224823, test 0.41537779569625854\n",
      "\n",
      "At iteration 160, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.91585\n",
      "The current cost: train 0.2950659692287445, test 0.3948991000652313\n",
      "\n",
      "At iteration 180, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.917\n",
      "The current cost: train 0.2874549925327301, test 0.3872316777706146\n",
      "\n",
      "At iteration 200, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.92335\n",
      "The current cost: train 0.265469491481781, test 0.366150826215744\n",
      "\n",
      "At iteration 220, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.92725\n",
      "The current cost: train 0.24988630414009094, test 0.3507198393344879\n",
      "\n",
      "At iteration 240, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9307\n",
      "The current cost: train 0.23877541720867157, test 0.3397728502750397\n",
      "\n",
      "At iteration 260, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9335\n",
      "The current cost: train 0.22882840037345886, test 0.33006751537323\n",
      "\n",
      "At iteration 280, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9367\n",
      "The current cost: train 0.21974016726016998, test 0.32134273648262024\n",
      "\n",
      "At iteration 300, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9392\n",
      "The current cost: train 0.2113955020904541, test 0.3134874999523163\n",
      "\n",
      "At iteration 320, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.94135\n",
      "The current cost: train 0.20366302132606506, test 0.30630913376808167\n",
      "\n",
      "At iteration 340, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.94325\n",
      "The current cost: train 0.19645991921424866, test 0.29976314306259155\n",
      "\n",
      "At iteration 360, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9452\n",
      "The current cost: train 0.18970735371112823, test 0.2937510907649994\n",
      "\n",
      "At iteration 380, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.94715\n",
      "The current cost: train 0.1833740621805191, test 0.28830066323280334\n",
      "\n",
      "At iteration 400, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.94885\n",
      "The current cost: train 0.17741607129573822, test 0.2832217514514923\n",
      "\n",
      "At iteration 420, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.95055\n",
      "The current cost: train 0.17179356515407562, test 0.27852457761764526\n",
      "\n",
      "At iteration 440, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9524\n",
      "The current cost: train 0.1664804071187973, test 0.2741847336292267\n",
      "\n",
      "At iteration 460, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9541\n",
      "The current cost: train 0.1614273488521576, test 0.27016058564186096\n",
      "\n",
      "At iteration 480, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9559\n",
      "The current cost: train 0.15662053227424622, test 0.2664179801940918\n",
      "\n",
      "At iteration 500, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9573\n",
      "The current cost: train 0.1520557999610901, test 0.26298248767852783\n",
      "\n",
      "At iteration 520, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.95865\n",
      "The current cost: train 0.14770616590976715, test 0.2597520351409912\n",
      "\n",
      "At iteration 540, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.95965\n",
      "The current cost: train 0.1435464471578598, test 0.2567126452922821\n",
      "\n",
      "At iteration 560, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.961\n",
      "The current cost: train 0.13956286013126373, test 0.2538851201534271\n",
      "\n",
      "At iteration 580, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.96235\n",
      "The current cost: train 0.13574863970279694, test 0.2511821985244751\n",
      "\n",
      "At iteration 600, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.96325\n",
      "The current cost: train 0.13208962976932526, test 0.24870221316814423\n",
      "\n",
      "At iteration 620, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9646\n",
      "The current cost: train 0.12858052551746368, test 0.24634526669979095\n",
      "\n",
      "At iteration 640, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9656\n",
      "The current cost: train 0.12520980834960938, test 0.24413426220417023\n",
      "\n",
      "At iteration 660, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.96685\n",
      "The current cost: train 0.12196104973554611, test 0.2420472800731659\n",
      "\n",
      "At iteration 680, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.96805\n",
      "The current cost: train 0.11882627010345459, test 0.24008958041667938\n",
      "\n",
      "At iteration 700, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9688\n",
      "The current cost: train 0.11580457538366318, test 0.23823174834251404\n",
      "\n",
      "At iteration 720, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.96975\n",
      "The current cost: train 0.11289332062005997, test 0.23643825948238373\n",
      "\n",
      "At iteration 740, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.97075\n",
      "The current cost: train 0.11008308082818985, test 0.23470282554626465\n",
      "\n",
      "At iteration 760, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9716\n",
      "The current cost: train 0.1073528453707695, test 0.23303820192813873\n",
      "\n",
      "At iteration 780, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9725\n",
      "The current cost: train 0.10470928996801376, test 0.23145724833011627\n",
      "\n",
      "At iteration 800, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.97295\n",
      "The current cost: train 0.10215068608522415, test 0.22995606064796448\n",
      "\n",
      "At iteration 820, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9738\n",
      "The current cost: train 0.09966856986284256, test 0.2285560816526413\n",
      "\n",
      "At iteration 840, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9746\n",
      "The current cost: train 0.09726866334676743, test 0.22720211744308472\n",
      "\n",
      "At iteration 860, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.97525\n",
      "The current cost: train 0.09493226557970047, test 0.2259727567434311\n",
      "\n",
      "At iteration 880, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9758\n",
      "The current cost: train 0.09266249090433121, test 0.22480078041553497\n",
      "\n",
      "At iteration 900, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9765\n",
      "The current cost: train 0.09046795964241028, test 0.2236526757478714\n",
      "\n",
      "At iteration 920, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.97705\n",
      "The current cost: train 0.08833538740873337, test 0.22257214784622192\n",
      "\n",
      "At iteration 940, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.97795\n",
      "The current cost: train 0.08626363426446915, test 0.22154253721237183\n",
      "\n",
      "At iteration 960, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.97825\n",
      "The current cost: train 0.08424621820449829, test 0.2205643355846405\n",
      "\n",
      "At iteration 980, the accuracy and cost are:\n",
      "The accuracy on the training set is 0.9788\n",
      "The current cost: train 0.0822857916355133, test 0.21963831782341003\n",
      "\n",
      "Training is complete!\n",
      "Final Training cost: 0.08047671616077423\n",
      "Final Testing cost: 0.2189733386039734\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        session.run(optimizer, feed_dict={X: X_train, Y: y_train_onehot})\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            training_cost = session.run(cost, feed_dict={X: X_train, Y:y_train_onehot})\n",
    "            testing_cost = session.run(cost, feed_dict={X: X_test, Y: y_test_onehot})\n",
    "            current_prediction = session.run(prediction, feed_dict={X: X_train, Y:y_train_onehot})\n",
    "            current_prediction = np.argmax(current_prediction, axis=1)\n",
    "            accuracy = sum(current_prediction==y_train) / len(y_train)\n",
    "            print(\"At iteration {}, the accuracy and cost are:\".format(i))\n",
    "            print(\"The accuracy on the training set is\", accuracy)\n",
    "            print(\"The current cost: train {}, test {}\\n\".format(training_cost, testing_cost))\n",
    "            \n",
    "    # Training is now complete!\n",
    "    print(\"Training is complete!\")\n",
    "\n",
    "    final_training_cost = session.run(cost, feed_dict={X: X_train, Y:y_train_onehot})\n",
    "    final_testing_cost = session.run(cost, feed_dict={X: X_test, Y: y_test_onehot})\n",
    "\n",
    "    print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "    print(\"Final Testing cost: {}\".format(final_testing_cost))\n",
    "    saver.save(session, \"./tmp/model.ckpt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Use pre-trained model to do classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/model.ckpt\n",
      "0.9345\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    saver.restore(session, \"./tmp/model.ckpt\")\n",
    "    current_prediction = session.run(prediction, feed_dict={X: X_test, Y:y_test_onehot})\n",
    "    current_prediction = np.argmax(current_prediction, axis=1)\n",
    "    accuracy = sum(current_prediction==y_test) / len(y_test)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/model.ckpt\n",
      "0.9345\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "session = tf.InteractiveSession()\n",
    "saver.restore(session, \"./tmp/model.ckpt\")\n",
    "current_prediction = session.run(prediction, feed_dict={X: X_test, Y:y_test_onehot})\n",
    "current_prediction = np.argmax(current_prediction, axis=1)\n",
    "accuracy = sum(current_prediction==y_test) / len(y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-bb86694c7514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3204\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3205\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3207\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5485\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    651\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    652\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 653\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage import io\n",
    "img = io.imread('unnamed.png', as_grey=True)\n",
    "from skimage.transform import resize as imresize\n",
    "img = imresize(img, (28,28))\n",
    "plt.imshow(img)\n",
    "print(img.shape)\n",
    "img = img.reshape((28*28))\n",
    "t = [0]*784\n",
    "for i in range(28*28):\n",
    "    if img[i] == 1:\n",
    "        t[i] = 1\n",
    "    else:\n",
    "        t[i] = 0\n",
    "t = np.array(t).reshape((1,28*28))\n",
    "plt.imshow(img.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_prediction = session.run(prediction, feed_dict={X: img.reshape((1,28*28))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.9045287,  -3.627249 ,   5.5116725,  15.277622 ,  -7.9098797,\n",
       "          8.731153 ,   4.331572 ,  -8.989726 ,   3.8060126, -10.708624 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More resources:\n",
    "https://www.tensorflow.org/\n",
    "https://pythonprogramming.net/machine-learning-tutorial-python-introduction/\n",
    "https://learningtensorflow.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks for coming!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
