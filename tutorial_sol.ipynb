{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Let's get started\n",
    "## Importing some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_digit(img):\n",
    "    \"\"\"\n",
    "    Display the vector as a 28*28 grayscale image.\n",
    "    \"\"\"\n",
    "    img = img.reshape((28,28))\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectoried_generate_onehot_vector(labels):\n",
    "    \"\"\"\n",
    "    Returns the onehot encoding of the labels. This is a vectorized version of the function.\n",
    "    \"\"\"\n",
    "    onehot = np.zeros((len(labels), 10))\n",
    "    onehot[np.arange(len(labels)), labels] = 1\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_onehot_vector(labels):\n",
    "    \"\"\"\n",
    "    Returns the onehot encoding of the labels.\n",
    "    \"\"\"\n",
    "    num_samples = len(labels)\n",
    "    onehot = np.zeros((num_samples, 10))\n",
    "    for i in range(num_samples):\n",
    "        label = labels[i]\n",
    "        onehot[i, label] = 1\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training set and testing set\n",
    "The dataset we are working with in this tutorial is the MNIST handwritten digit dataset.\n",
    "There are 60000 training examples and 10000 testing examples. We will only use 20000 of the trainig examples and 2000 of the testing examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"X_train.npy\")[:20000,:\n",
    "y_train = np.load(\"y_train.npy\")[:20000]\n",
    "X_test = np.load(\"X_test.npy\")[:2000,:]\n",
    "y_test = np.load(\"y_test.npy\")[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the first trainig sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_digit(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [sklearn.preprocessing.StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to normalize the data.\n",
    "Try what would happen if you don't normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the labels to one hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = generate_onehot_vector(y_train)\n",
    "y_test_onehot = vectoried_generate_onehot_vector(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Setting up the neural network\n",
    "\n",
    "In this tutorial, we will use a neural network with three fully connected hidden layers. We will explore how different hyperparamter choices affect the performance of our neural network. Let's first set up some hyperparameters for our net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "iterations = 1000\n",
    "layer_1_nodes = 150\n",
    "layer_2_nodes = 150\n",
    "layer_3_nodes = 150\n",
    "layer_4_nodes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up neural network\n",
    "tf.placeholder is a variable to which we will assign values to at the later stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the layers of our neural net to our [\"Computational Graph\"]([https://www.tensorflow.org/programmers_guide/graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.random_normal(shape=[784, layer_1_nodes], \n",
    "                                           dtype=tf.float32,\n",
    "                                           stddev=1e-1),\n",
    "                                           name=\"weights1\")\n",
    "b1 = tf.Variable(tf.constant(0.0, shape=[layer_1_nodes], dtype=tf.float32), name=\"biases1\")\n",
    "\n",
    "layer_1_output = tf.nn.relu(tf.matmul(X, w1) + b1)\n",
    "\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal(shape=[layer_1_nodes, layer_2_nodes], \n",
    "                                           dtype=tf.float32,\n",
    "                                           stddev=1e-1),\n",
    "                                           name=\"weights2\")\n",
    "b2 = tf.Variable(tf.constant(0.0, shape=[layer_2_nodes], dtype=tf.float32), name=\"biases2\")\n",
    "\n",
    "layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, w2) + b2)\n",
    "\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal(shape=[layer_2_nodes, layer_3_nodes], \n",
    "                                           dtype=tf.float32,\n",
    "                                           stddev=1e-1),\n",
    "                                           name=\"weights3\")\n",
    "b3 = tf.Variable(tf.constant(0.0, shape=[layer_3_nodes], dtype=tf.float32), name=\"biases3\")\n",
    "\n",
    "layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, w3) + b3)\n",
    "\n",
    "w4 = tf.Variable(tf.random_normal(shape=[layer_3_nodes, layer_4_nodes], \n",
    "                                           dtype=tf.float32,\n",
    "                                           stddev=1e-1),\n",
    "                                           name=\"weights4\")\n",
    "b4 = tf.Variable(tf.constant(0.0, shape=[layer_4_nodes], dtype=tf.float32), name=\"biases4\")\n",
    "\n",
    "layer_4_output = tf.matmul(layer_3_output, w4) + b4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choices of loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = layer_4_output\n",
    "cost = tf.losses.softmax_cross_entropy(logits=prediction, onehot_labels=Y)\n",
    "# cost = tf.reduce_mean(tf.squared_difference(prediction, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saver = tf.train.Saver() # for part3\n",
    "\n",
    "session = tf.InteractiveSession()\n",
    "    \n",
    "session.run(tf.global_variables_initializer())\n",
    "    \n",
    "for i in range(iterations):\n",
    "    session.run(optimizer, feed_dict={X: X_train, Y: y_train_onehot})\n",
    "        \n",
    "    if i % 20 == 0:\n",
    "        training_cost = session.run(cost, feed_dict={X: X_train, Y:y_train_onehot})\n",
    "        current_prediction = session.run(prediction, feed_dict={X: X_train, Y:y_train_onehot})\n",
    "        current_prediction = np.argmax(current_prediction, axis=1)\n",
    "        accuracy = sum(current_prediction==y_train) / len(y_train)\n",
    "        print(\"At iteration {}, the accuracy and cost are:\".format(i))\n",
    "        print(\"The accuracy on the training set is\", accuracy)\n",
    "        print(\"The current training cost: {}\\n\".format(training_cost))\n",
    "            \n",
    "# Training is now complete!\n",
    "print(\"Training is complete!\")\n",
    "\n",
    "final_training_cost = session.run(cost, feed_dict={X: X_train, Y:y_train_onehot})\n",
    "final_testing_cost = session.run(cost, feed_dict={X: X_test, Y: y_test_onehot})\n",
    "\n",
    "print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "print(\"Final Testing cost: {}\".format(final_testing_cost))\n",
    "# saver.save(session, \"./tmp/model.ckpt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Extra)Part 3: Save \n",
    "https://www.tensorflow.org/guide/saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    saver.restore(session, \"./tmp/model.ckpt\")\n",
    "    current_prediction = session.run(prediction, feed_dict={X: X_test, Y:y_test_onehot})\n",
    "    current_prediction = np.argmax(current_prediction, axis=1)\n",
    "    accuracy = sum(current_prediction==y_test) / len(y_test)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "session = tf.InteractiveSession()\n",
    "saver.restore(session, \"./tmp/model.ckpt\")\n",
    "current_prediction = session.run(prediction, feed_dict={X: X_test, Y:y_test_onehot})\n",
    "current_prediction = np.argmax(current_prediction, axis=1)\n",
    "accuracy = sum(current_prediction==y_test) / len(y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More resources:\n",
    "https://www.tensorflow.org/\n",
    "https://pythonprogramming.net/machine-learning-tutorial-python-introduction/\n",
    "https://learningtensorflow.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks for coming!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
